{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid sentiment analysis Tensorflow RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noahkandie/Covid-19-Tweets-sentiment-analalysis/blob/main/Covid_sentiment_analysis_Tensorflow_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ788-SHhJIH",
        "outputId": "8163e63e-dd70-4679-fc98-46f6606e8bdf"
      },
      "source": [
        "\n",
        "!pip install wandb\n",
        "!wandb login"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.7)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.2.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: yaspin>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.24)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (3.10.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoahkandie\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nHEow6otjVT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.distribute import distribution_strategy_context\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.framework import smart_cond\n",
        "from tensorflow.python.framework import tensor_util\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils import losses_utils\n",
        "from tensorflow.python.keras.utils import tf_utils\n",
        "from tensorflow.python.keras.utils.generic_utils import deserialize_keras_object\n",
        "from tensorflow.python.keras.utils.generic_utils import serialize_keras_object\n",
        "from tensorflow.python.ops import array_ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "from tensorflow.python.ops import nn\n",
        "from tensorflow.python.ops.losses import losses_impl\n",
        "from tensorflow.python.ops.losses import util as tf_losses_util\n",
        "from tensorflow.python.util.tf_export import keras_export\n",
        "from tensorflow.tools.docs import doc_controls"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFck8nmQhZTM"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDcJbjustiWI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2zDoKBapdkY"
      },
      "source": [
        "# #Initialize wandb\n",
        "\n",
        "# wandb.init(project='gpt3', entity='alpha-coders')\n",
        "# config={  # and include hyperparameters and metadata\n",
        "#                      \"learning_rate\": 0.005,\n",
        "#                      \"epochs\": 5,\n",
        "#                      \"batch_size\": 64,\n",
        "#                      \"loss_function\": \"sparse_categorical_crossentropy\",\n",
        "#                      \"architecture\": \"RNN\"}\n",
        "# # 2. Save model inputs and hyperparameters\n",
        "# config = wandb.config"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1anyRMp6hr_P"
      },
      "source": [
        "\n",
        "# for i in range(10):\n",
        "#   log_dict = {\n",
        "#       \"train_loss\": 1/(i+1),\n",
        "#       \"custom_step\": i**2,\n",
        "#       \"validation_loss\": 1/(i+1) }\n",
        "# wandb.log(log_dict)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HncEmTTThwil"
      },
      "source": [
        "wandb.config.dropout = 0.2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyohllIzAeyv"
      },
      "source": [
        "Modelling using Tensorflow hub using a pretrained word embedding layer to classify tweets on climate change into classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITti9yg8j2j_",
        "outputId": "7a33b1ac-be80-4fa4-f63f-d7cea3e7919f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#for text pre-processing\n",
        "import re, string\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "#for model-building\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "# bag of words\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#for word embedding\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.util import ngrams\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "import spacy\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "  \n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz8ygJLT_3vY"
      },
      "source": [
        "## Load and preview data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srxFf8KSjaIe"
      },
      "source": [
        "df = pd.read_csv('/content/Covid wk sentiments.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "GQfX9c_Lloas",
        "outputId": "0ba7bd25-cb8d-498d-e0d0-2a54c89777b2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>created_at</th>\n",
              "      <th>vaccine</th>\n",
              "      <th>town</th>\n",
              "      <th>country</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>week</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020 BioNTech &amp;amp; Pfizer announce their COVI...</td>\n",
              "      <td>Nairobi, Kenya</td>\n",
              "      <td>2021-11-09 06:41:56</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Nairobi</td>\n",
              "      <td>Kenya</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>41.0</td>\n",
              "      <td>biontech amp pfizer announce covid vaccine eff...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@NamanyaRacheal2 @UgandaBreweries @centurybott...</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:45:27</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>45.0</td>\n",
              "      <td>namanyaracheal ugandabreweries centurybottling...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.777, 'pos': 0.223, 'comp...</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>.@MinofHealthUG received a total of 3.4 millio...</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:20:05</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20.0</td>\n",
              "      <td>minofhealthug receive total million dose covid...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>@Case18640259 I think pfizer is the worst</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:09:20</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>case think pfizer worst</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.577, 'neu': 0.423, 'pos': 0.0, 'comp...</td>\n",
              "      <td>-0.6249</td>\n",
              "      <td>negative</td>\n",
              "      <td>strongly negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>On Sunday we got more vaccines from @usmission...</td>\n",
              "      <td>soroti</td>\n",
              "      <td>2021-11-09 03:43:24</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>soroti</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>43.0</td>\n",
              "      <td>sunday get vaccine usmissionuganda abt million...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...         sentiment2\n",
              "0           0  ...           positive\n",
              "1           1  ...           positive\n",
              "2           2  ...            neutral\n",
              "3           3  ...  strongly negative\n",
              "4           4  ...            neutral\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PYtz3VTmJvK",
        "outputId": "a005a32a-ad59-457e-e94d-11addf98106f"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'tweet', 'location', 'created_at', 'vaccine', 'town',\n",
              "       'country', 'date', 'year', 'month', 'day', 'hour', 'minute',\n",
              "       'clean_text', 'week', 'scores', 'compound', 'sentiment', 'sentiment2'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "wPWAKW_fnzcA",
        "outputId": "ee49935b-484a-4e5d-fbd4-c8d00c39a82b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>created_at</th>\n",
              "      <th>vaccine</th>\n",
              "      <th>town</th>\n",
              "      <th>country</th>\n",
              "      <th>date</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>hour</th>\n",
              "      <th>minute</th>\n",
              "      <th>clean_text</th>\n",
              "      <th>week</th>\n",
              "      <th>scores</th>\n",
              "      <th>compound</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentiment2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020 BioNTech &amp;amp; Pfizer announce their COVI...</td>\n",
              "      <td>Nairobi, Kenya</td>\n",
              "      <td>2021-11-09 06:41:56</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Nairobi</td>\n",
              "      <td>Kenya</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>41.0</td>\n",
              "      <td>biontech amp pfizer announce covid vaccine eff...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.763, 'pos': 0.237, 'comp...</td>\n",
              "      <td>0.4767</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>@NamanyaRacheal2 @UgandaBreweries @centurybott...</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:45:27</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>45.0</td>\n",
              "      <td>namanyaracheal ugandabreweries centurybottling...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.777, 'pos': 0.223, 'comp...</td>\n",
              "      <td>0.3182</td>\n",
              "      <td>positive</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>.@MinofHealthUG received a total of 3.4 millio...</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:20:05</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>20.0</td>\n",
              "      <td>minofhealthug receive total million dose covid...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>@Case18640259 I think pfizer is the worst</td>\n",
              "      <td>Kampala, Uganda</td>\n",
              "      <td>2021-11-09 05:09:20</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>Kampala</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>case think pfizer worst</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.577, 'neu': 0.423, 'pos': 0.0, 'comp...</td>\n",
              "      <td>-0.6249</td>\n",
              "      <td>negative</td>\n",
              "      <td>strongly negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>On Sunday we got more vaccines from @usmission...</td>\n",
              "      <td>soroti</td>\n",
              "      <td>2021-11-09 03:43:24</td>\n",
              "      <td>Pfizer-BioNTech</td>\n",
              "      <td>soroti</td>\n",
              "      <td>Uganda</td>\n",
              "      <td>2021-11-09</td>\n",
              "      <td>2021.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>9</td>\n",
              "      <td>3</td>\n",
              "      <td>43.0</td>\n",
              "      <td>sunday get vaccine usmissionuganda abt million...</td>\n",
              "      <td>Week 1</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>neutral</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...         sentiment2\n",
              "0           0  ...           positive\n",
              "1           1  ...           positive\n",
              "2           2  ...            neutral\n",
              "3           3  ...  strongly negative\n",
              "4           4  ...            neutral\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0i_3TGfoUGV"
      },
      "source": [
        "#df.to_csv('clean classified data.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC2nwWRk2lBT"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0F0cSzKtLC9"
      },
      "source": [
        "df['label']=df['sentiment']"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3FsKzxGYCx1"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8znjJJrxyky"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['clean_text'])\n",
        "\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_b8q01drwqY"
      },
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "hUgLaDZVtvqn",
        "outputId": "6a521e22-47ee-4e96-92a3-3e8360b484eb"
      },
      "source": [
        "#check the class distriburion\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "print(df['label'].value_counts())\n",
        "x=df['label'].value_counts()\n",
        "f, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(x.index,x)\n",
        "plt.gca().set_ylabel('class size')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "neutral     5459\n",
            "positive    4429\n",
            "negative    2648\n",
            "Name: label, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'class size')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCbK2jmpn0j5"
      },
      "source": [
        "# from sklearn import preprocessing\n",
        "# le = preprocessing.LabelEncoder()\n",
        "# df['class1'] = le.fit_transform(df['class'])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU70TjKjv3lP",
        "outputId": "c418fc54-fe87-47bb-a4a0-c4a92c93b065"
      },
      "source": [
        "! pip install wordcloud"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPH--4DWv8T2"
      },
      "source": [
        "# from wordcloud import WordCloud\n",
        "# import matplotlib.pyplot as plt\n",
        "# wc = WordCloud()\n",
        "# wc.generate(df.clean_text)\n",
        "# plt.imshow(wc, interpolation=\"bilinear\")\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2e_PYE53wV0"
      },
      "source": [
        "## Dealing with class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IuflS2S3ya7"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import datetime\n",
        "import tensorflow_hub as hub\n",
        "from __future__ import absolute_import,division,print_function,unicode_literals"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNVobV773JYx",
        "outputId": "1dee6355-664a-4d13-e337-c8ebb845782e"
      },
      "source": [
        "# Get the counts of the target classes\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     5459\n",
              "positive    4429\n",
              "negative    2648\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHRncDG-2qWF"
      },
      "source": [
        "# We split the dataset to train and test datasets, 80/20 split \n",
        "X_train,X_test,y_train,y_test=train_test_split(df,df[\"label\"],test_size=0.2,random_state=111,)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcUPYyEdCaNa"
      },
      "source": [
        "We are going to assign class weights to deal with imbalance. Due to the difference in each class, the algorithms tend to get biased towards the majority values present and don’t perform well on the minority values.\n",
        "\n",
        "The difference in weights will influence the classification of the classes during the training phase. The whole purpose is to penalize the misclassification made by the minority class by setting a higher class weight and at the same time reducing weight for the majority class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge935DLv1yhm"
      },
      "source": [
        "# We compute classweights\n",
        "from sklearn.utils import class_weight\n",
        "class_weights=list(class_weight.compute_class_weight('balanced',classes = np.unique(df['label']),y =df['label']))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class_weights = compute_class_weight(\n",
        "#                                         class_weight = \"balanced\",\n",
        "#                                         classes = np.unique(train_classes),\n",
        "#                                         y = train_classes                                                    \n",
        "#                                     )\n",
        "# class_weights = dict(zip(np.unique(train_classes), class_weights)),\n",
        "# class_weights"
      ],
      "metadata": {
        "id": "cPg2vP9SdbwP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOTbFqws2dpk",
        "outputId": "e88cd25a-099e-4a03-d75c-b12dc60a7d6c"
      },
      "source": [
        "# We sort the class weights \n",
        "class_weights.sort()\n",
        "class_weights"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7654637601514319, 0.9434785880936254, 1.5780463242698892]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eeOknj42grd"
      },
      "source": [
        "# we encode the target classes and assigning the class weights to each class index\n",
        "weights={}\n",
        "for index, weight in enumerate(class_weights):\n",
        "  weights[index]=weight"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lN-OMfp43iTW",
        "outputId": "016240c3-5ef1-430d-e687-297dae9ef2a6"
      },
      "source": [
        "weights"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.7654637601514319, 1: 0.9434785880936254, 2: 1.5780463242698892}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL3jbvWq6jkz",
        "outputId": "0d1d988a-2204-4d02-b7b4-f92ec53f119a"
      },
      "source": [
        "#  Check the columns\n",
        "df.columns"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'tweet', 'location', 'created_at', 'vaccine', 'town',\n",
              "       'country', 'date', 'year', 'month', 'day', 'hour', 'minute',\n",
              "       'clean_text', 'week', 'scores', 'compound', 'sentiment', 'sentiment2',\n",
              "       'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8f-eC5t4GkN"
      },
      "source": [
        "# Coverting the datasets into tensors. We feed the input X value and product\n",
        "dataset_train=tf.data.Dataset.from_tensor_slices((X_train['clean_text'].values,X_train['label'].values))\n",
        "dataset_test=tf.data.Dataset.from_tensor_slices((X_test['clean_text'].values,X_test['label'].values))"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J0REEtp6cAT"
      },
      "source": [
        "# Coverting the datasets into tensors. We feed the input X value and product\n",
        "dataset_train=tf.data.Dataset.from_tensor_slices((X_train['clean_text'].values,X_train['label'].values))\n",
        "dataset_test=tf.data.Dataset.from_tensor_slices((X_test['clean_text'].values,X_test['label'].values))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkArLUej4lFc",
        "outputId": "562b63fb-0e3e-4f28-f26b-2d32bfff7f04"
      },
      "source": [
        "# Print text and target columns\n",
        "for text, target in dataset_train.take(5):\n",
        "  print('Tweet:{},Target:{}'.format(text,target))\n",
        "print('************************')\n",
        "for text, target in dataset_test.take(5):\n",
        "  print('Tweet:{},Target:{}'.format(text,target))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet:b'kariukinduva way ensure maximum protection love one get vaccine',Target:b'positive'\n",
            "Tweet:b'today november million covid vaccine administer across african contine',Target:b'neutral'\n",
            "Tweet:b'trump deal moderna hamper global vaccine effort gt',Target:b'positive'\n",
            "Tweet:b'minofhealthug ainbyoo janeruth aceng johnson amp johnson vaccine uganda vaccination list yes get',Target:b'positive'\n",
            "Tweet:b'kiuvarsity allow come nd jab pfizer',Target:b'positive'\n",
            "************************\n",
            "Tweet:b'husband woman die covid without chance meet newborn baby plead people',Target:b'negative'\n",
            "Tweet:b'covid vaccine ugx billion country overwhelm borrow appetite discussion',Target:b'negative'\n",
            "Tweet:b'fully vaccinate believe vaccine work nobody forced get maintain',Target:b'negative'\n",
            "Tweet:b'covid vaccine safe effective',Target:b'positive'\n",
            "Tweet:b'rwandahealth drmpunga nsanzimanasabin drdanielngamije rbcrwanda really good parent would app',Target:b'positive'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmfVD16YBkWR",
        "outputId": "27164b4a-8d33-47ce-8aba-74b8f0120a8f"
      },
      "source": [
        "df['label'].unique()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['positive', 'neutral', 'negative'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9m76O2f6LnI"
      },
      "source": [
        "# Convert target column from string to numerical using tensorflow lookup hash table\n",
        "table=tf.lookup.StaticHashTable(\n",
        "    initializer=tf.lookup.KeyValueTensorInitializer(\n",
        "        keys=tf.constant(['neutral','positive','negative']),\n",
        "        values=tf.constant([0,1,2]),\n",
        "    ),\n",
        "    default_value=tf.constant(-1),\n",
        "    name='target_encoding'\n",
        ")\n",
        "@tf.function #converts regular python code to a callable Tensorflow graph function, \n",
        "              #which is usually more performant and python independent\n",
        "def target(x):\n",
        "  return table.lookup(x)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbvok71x7ipY"
      },
      "source": [
        "# Callable fi=unction that returns the class of text\n",
        "def show_batch(dataset,size=5):\n",
        "  for batch,label in dataset.take(size):\n",
        "    print(batch.numpy())\n",
        "    print(target(label).numpy())"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyHsKuPB79Iy",
        "outputId": "61ae962a-f50f-4b82-81b3-d95da65200cc"
      },
      "source": [
        "show_batch(dataset_test,5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'husband woman die covid without chance meet newborn baby plead people'\n",
            "2\n",
            "b'covid vaccine ugx billion country overwhelm borrow appetite discussion'\n",
            "2\n",
            "b'fully vaccinate believe vaccine work nobody forced get maintain'\n",
            "2\n",
            "b'covid vaccine safe effective'\n",
            "1\n",
            "b'rwandahealth drmpunga nsanzimanasabin drdanielngamije rbcrwanda really good parent would app'\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufdVFRTBHtR2"
      },
      "source": [
        "We can print n-rows of target column and their target classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-xZiPwm_tvp"
      },
      "source": [
        "# Creating a fetch function to pass and return text value as is. Also we one encode the target value\n",
        "def fetch(text,labels):\n",
        "  return text,tf.one_hot(target(labels),3)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abdNHVPBAFH8"
      },
      "source": [
        "\n",
        "# Map the fetch function to the train and test dataset \n",
        "train_data_f=dataset_train.map(fetch)\n",
        "test_data_f=dataset_test.map(fetch)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ysw-fnsGAOd7",
        "outputId": "5c6d4aac-a6a4-4b6f-b4df-e4082bd62d4b"
      },
      "source": [
        "next(iter(train_data_f))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'kariukinduva way ensure maximum protection love one get vaccine'>,\n",
              " <tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 0.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3OBpE4RAZ5g",
        "outputId": "518212fe-1f0d-4fde-bf3a-a43899467601"
      },
      "source": [
        "# Creates batches of tensors in tensors\n",
        "train_data,train_labels=next(iter(train_data_f.batch(5)))\n",
        "train_data,train_labels"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(5,), dtype=string, numpy=\n",
              " array([b'kariukinduva way ensure maximum protection love one get vaccine',\n",
              "        b'today november million covid vaccine administer across african contine',\n",
              "        b'trump deal moderna hamper global vaccine effort gt',\n",
              "        b'minofhealthug ainbyoo janeruth aceng johnson amp johnson vaccine uganda vaccination list yes get',\n",
              "        b'kiuvarsity allow come nd jab pfizer'], dtype=object)>,\n",
              " <tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
              " array([[0., 1., 0.],\n",
              "        [1., 0., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.],\n",
              "        [0., 1., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ8_T2hWBGeo",
        "outputId": "0c0ea9d4-d229-4bee-e07e-233aa813fc1f"
      },
      "source": [
        "# Creating a embedding layer by using pretrained embedding layer to enable us to convert each word into a fixed length vector of defined size\n",
        "embedding='https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1'\n",
        "hub_layer=hub.KerasLayer(embedding,output_shape=[128],input_shape=[],\n",
        "                        dtype=tf.string,trainable=True)# The output shape is 128\n",
        "hub_layer(train_data[:1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128), dtype=float32, numpy=\n",
              "array([[ 0.1449583 ,  0.09494543, -0.01786795, -0.08353036,  0.0597224 ,\n",
              "        -0.07519454,  0.15088914, -0.02465569, -0.0777173 ,  0.10039251,\n",
              "        -0.01308313, -0.09102555, -0.06544387, -0.07597445, -0.09813565,\n",
              "        -0.212876  ,  0.03122438, -0.23222446, -0.23988625, -0.02765726,\n",
              "         0.13352206, -0.18612218,  0.14813179,  0.0046863 , -0.00522918,\n",
              "         0.04647572,  0.15353565,  0.06872246, -0.11100654, -0.07106032,\n",
              "         0.12768678, -0.08142728,  0.07988252,  0.1663512 ,  0.11841448,\n",
              "        -0.01720551, -0.05336679, -0.04232255,  0.06148271,  0.08851826,\n",
              "        -0.07047053, -0.09623756,  0.04211065,  0.08356252, -0.12032764,\n",
              "         0.01488401,  0.00441692,  0.12971978,  0.08465832, -0.10400324,\n",
              "         0.01638552, -0.10752864, -0.01562833,  0.03227586, -0.0065481 ,\n",
              "         0.002677  , -0.07966583, -0.09562691, -0.04132988,  0.0417532 ,\n",
              "        -0.00358938,  0.22456482,  0.04235281, -0.14851968, -0.05028027,\n",
              "         0.08412396,  0.12053327,  0.03924425,  0.05433304,  0.15746629,\n",
              "         0.00190773, -0.00538097, -0.06360622, -0.03901054,  0.06663117,\n",
              "         0.06873077,  0.02980116, -0.09220781, -0.13303673, -0.0652612 ,\n",
              "         0.08289646,  0.20742427, -0.14680114,  0.1611438 ,  0.03142866,\n",
              "        -0.06066441, -0.0737636 , -0.03912747,  0.16773754,  0.3313322 ,\n",
              "         0.00881803,  0.03324947, -0.00786176, -0.07972139,  0.12332203,\n",
              "         0.02383697, -0.11442732, -0.08893734, -0.16965508, -0.17019671,\n",
              "         0.0195496 , -0.05635123, -0.08687501, -0.00570983, -0.1096684 ,\n",
              "         0.14237061,  0.04000068,  0.18524063, -0.09993736, -0.14392099,\n",
              "        -0.21620575, -0.01334152, -0.00563149,  0.02473706, -0.09749696,\n",
              "         0.07307728,  0.02187577,  0.02352886, -0.01277933,  0.13078922,\n",
              "         0.05432374, -0.14759459, -0.00516579, -0.13240342, -0.14677702,\n",
              "        -0.11672285,  0.11254728,  0.18918763]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BITcisXQDNMT",
        "outputId": "b064d6fc-aa6f-4628-8b57-366a24e5f5ef"
      },
      "source": [
        "# We create a keras sequential model.\n",
        "# Sequential groups a linear stack of layers into a tf.keras.Model.\n",
        "# Sequential provides training and inference features on this model.\n",
        "\n",
        "model=tf.keras.Sequential()\n",
        "model.add(hub_layer)\n",
        "for units in [128,128,64,32]:\n",
        "  model.add(tf.keras.layers.Dense(units,activation='relu'))\n",
        "  model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "# We specify the output as 6 predicted values \n",
        "model.add(tf.keras.layers.Dense(3,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 128)               124642688 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,686,147\n",
            "Trainable params: 124,686,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RXHOVzWJxG6R",
        "outputId": "99401498-b80f-4d74-d619-80a38e9668e9"
      },
      "source": [
        "# #Initialize wandb\n",
        "\n",
        "wandb.init(project='gpt3', entity='alpha-coders',save_code=True)\n",
        "config={  # and include hyperparameters and metadata\n",
        "                      \"epochs\": 10,\n",
        "                      \"batch_size\": 512,\n",
        "                      \"architecture\": \"RNN\",\n",
        "                      \"loss_function\": \"categorical_crossentropy\",'sparcse'\n",
        "                      'optimizer':'adam'}\n",
        "# 2. Save model inputs and hyperparameters\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.005"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnoahkandie\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/alpha-coders/gpt3/runs/3ef7v7td\" target=\"_blank\">charmed-glade-77</a></strong> to <a href=\"https://wandb.ai/alpha-coders/gpt3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI4C3PBWVL4M"
      },
      "source": [
        "# # Initialize wandb with your project name\n",
        "# run = wandb.init(project='my-keras-integration',\n",
        "#                  config={  # and include hyperparameters and metadata\n",
        "#                      \"learning_rate\": 0.01,\n",
        "#                      \"epochs\": 20,\n",
        "#                      \"batch_size\": 128,\n",
        "#                      \"loss_function\": \"sparce categorical_crossentropy\",\n",
        "#                      \"architecture\": \"RNN\",\n",
        "#                      \"dataset\": \"df\"\n",
        "#                      })"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw12IBRVEHzA",
        "outputId": "6a2cad5b-d80f-4bd1-9c7b-be7dd7c0b1b8"
      },
      "source": [
        "\n",
        "# We compile using adam optimizer\n",
        "config = wandb.config  # We'll use this to configure our experiment\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model.summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(config.learning_rate),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.Precision()])\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 128)               124642688 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,686,147\n",
            "Trainable params: 124,686,147\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpVvvzQYMCYV"
      },
      "source": [
        "We will evaluate the model using different metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGWJkJQsEc70"
      },
      "source": [
        "# We shuffle and train the train and test data\n",
        "train_data_f=train_data_f.shuffle(70000).batch(512)\n",
        "test_data_f=test_data_f.batch(512)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5wiY50UQMkS"
      },
      "source": [
        "\n",
        "# Create a copy of our model\n",
        "model2=model"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSUYh7EzEuAj",
        "outputId": "589d08fd-907d-4777-b05b-458d9b089a8f"
      },
      "source": [
        "# we train the data using 10 epochs and using class weights. bias is therefore introduced to the model and computed.\n",
        "# we will perform checks to ensure each class performs well\n",
        "history=model.fit(train_data_f,epochs=10,\n",
        "                  validation_data=test_data_f, \n",
        "                  verbose=2,\n",
        "                  callbacks=[WandbCallback()])\n",
        "#model.save(os.path.join(wandb.run.dir, \"model.h5\"))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 - 42s - loss: 0.9052 - precision: 0.7246 - val_loss: 0.5933 - val_precision: 0.8033 - 42s/epoch - 2s/step\n",
            "Epoch 2/10\n",
            "20/20 - 31s - loss: 0.3636 - precision: 0.8971 - val_loss: 0.3968 - val_precision: 0.8817 - 31s/epoch - 2s/step\n",
            "Epoch 3/10\n",
            "20/20 - 26s - loss: 0.1206 - precision: 0.9691 - val_loss: 0.4672 - val_precision: 0.8877 - 26s/epoch - 1s/step\n",
            "Epoch 4/10\n",
            "20/20 - 26s - loss: 0.0535 - precision: 0.9870 - val_loss: 0.6075 - val_precision: 0.8847 - 26s/epoch - 1s/step\n",
            "Epoch 5/10\n",
            "20/20 - 26s - loss: 0.0325 - precision: 0.9930 - val_loss: 0.7084 - val_precision: 0.8804 - 26s/epoch - 1s/step\n",
            "Epoch 6/10\n",
            "20/20 - 26s - loss: 0.0271 - precision: 0.9943 - val_loss: 0.7134 - val_precision: 0.8820 - 26s/epoch - 1s/step\n",
            "Epoch 7/10\n",
            "20/20 - 26s - loss: 0.0150 - precision: 0.9961 - val_loss: 0.8719 - val_precision: 0.8800 - 26s/epoch - 1s/step\n",
            "Epoch 8/10\n",
            "20/20 - 26s - loss: 0.0101 - precision: 0.9972 - val_loss: 1.0822 - val_precision: 0.8728 - 26s/epoch - 1s/step\n",
            "Epoch 9/10\n",
            "20/20 - 26s - loss: 0.0093 - precision: 0.9971 - val_loss: 1.1434 - val_precision: 0.8713 - 26s/epoch - 1s/step\n",
            "Epoch 10/10\n",
            "20/20 - 26s - loss: 0.0258 - precision: 0.9949 - val_loss: 0.9029 - val_precision: 0.8715 - 26s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQLGlj5-_R9m",
        "outputId": "3f66a49c-5f4a-4dbd-980e-ac10fdf75d25"
      },
      "source": [
        "loss, accuracy = model.evaluate(dataset_test.map(fetch).batch(1121),verbose=2)\n",
        "print('Test Error Rate: ', round((1 - accuracy) * 100, 2))\n",
        "\n",
        "# With wandb.log, we can easily pass in metrics as key-value pairs.\n",
        "wandb.log({'Test Error Rate': round((1 - accuracy) * 100, 2)})\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 - 1s - loss: 0.9029 - precision: 0.8715 - 519ms/epoch - 173ms/step\n",
            "Test Error Rate:  12.85\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS2CIbANE-uM",
        "outputId": "8ff06695-40a9-46f7-fa4b-5722a42b8831"
      },
      "source": [
        "# check the length of the test dataset\n",
        "len(list(dataset_test))\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2508"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YczDI9h3FQ0I",
        "outputId": "27b0aa37-f465-4057-a03b-ee2c27d6ebb3"
      },
      "source": [
        "# craete a batch of the dataset and pass the model through entire dataset\n",
        "results=model.evaluate(dataset_test.map(fetch).batch(1121),verbose=2)\n",
        "print(results)\n",
        "\n",
        "# we pass model through the test data and map the fetch function.\n",
        "test_data,test_labels=next(iter(dataset_test.map(fetch).batch(10000)))\n",
        "# Predict the target class\n",
        "y_pred=model.predict(test_data)\n",
        "# Check the model performance using classification and confusion matrix\n",
        "\n",
        "from sklearn import metrics\n",
        "print('Mean Absolute Error:', metrics.mean_absolute_error(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))\n",
        "print('Mean Squared Error:', metrics.mean_squared_error(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))\n",
        "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1))))\n",
        "print('The accuracy of the model is ',metrics.accuracy_score(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))\n",
        "print('The precision score is: ',metrics.precision_score(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1),average='weighted'))\n",
        "print('The F1 score is: ',metrics.f1_score(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1),average='weighted'))\n",
        "print('The recall score is ',metrics.recall_score(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1),average='weighted'))\n",
        "print('\\n', 'Confusion matrix')\n",
        "print(confusion_matrix(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))\n",
        "print('\\n', 'Classification report')\n",
        "print(classification_report(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 - 0s - loss: 0.9029 - precision: 0.8715 - 496ms/epoch - 165ms/step\n",
            "[0.9028627872467041, 0.8715375065803528]\n",
            "Mean Absolute Error: 0.17105263157894737\n",
            "Mean Squared Error: 0.24681020733652312\n",
            "Root Mean Squared Error: 0.4967999671261293\n",
            "The accuracy of the model is  0.8668261562998405\n",
            "The precision score is:  0.8672051329798888\n",
            "The F1 score is:  0.8667687114612335\n",
            "The recall score is  0.8668261562998405\n",
            "\n",
            " Confusion matrix\n",
            "[[947  75  48]\n",
            " [ 49 805  50]\n",
            " [ 47  65 422]]\n",
            "\n",
            " Classification report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      1070\n",
            "           1       0.85      0.89      0.87       904\n",
            "           2       0.81      0.79      0.80       534\n",
            "\n",
            "    accuracy                           0.87      2508\n",
            "   macro avg       0.86      0.86      0.86      2508\n",
            "weighted avg       0.87      0.87      0.87      2508\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFkoDNf9Nzqc"
      },
      "source": [
        "The accuracy of the model is 83%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-t7lfKwFvPl"
      },
      "source": [
        "# we pass model through the test data and map the fetch function.\n",
        "test_data,test_labels=next(iter(dataset_test.map(fetch).batch(10000)))\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2q7Zj7CFqUG",
        "outputId": "8bba8d14-7487-4c81-f161-c6c26e9c1f49"
      },
      "source": [
        "# Predict the target class\n",
        "y_pred=model.predict(test_data)\n",
        "# Check the model performance using classification and confusion matrix\n",
        "print(classification_report(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      1070\n",
            "           1       0.85      0.89      0.87       904\n",
            "           2       0.81      0.79      0.80       534\n",
            "\n",
            "    accuracy                           0.87      2508\n",
            "   macro avg       0.86      0.86      0.86      2508\n",
            "weighted avg       0.87      0.87      0.87      2508\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oachM-6WGy7C"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqDMASvaGeXF",
        "outputId": "78c2a599-bf4b-44a2-e905-074304af1865"
      },
      "source": [
        "# Check the model performance using classification and confusion matrix\n",
        "print(classification_report(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1)))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90      1070\n",
            "           1       0.85      0.89      0.87       904\n",
            "           2       0.81      0.79      0.80       534\n",
            "\n",
            "    accuracy                           0.87      2508\n",
            "   macro avg       0.86      0.86      0.86      2508\n",
            "weighted avg       0.87      0.87      0.87      2508\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbD4QqoDQ1qW",
        "outputId": "c5dc7218-a568-4617-a593-842b87683afd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_labels.numpy().argmax(axis=1),y_pred.argmax(axis=1))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[947,  75,  48],\n",
              "       [ 49, 805,  50],\n",
              "       [ 47,  65, 422]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTIQqEW78Ruq"
      },
      "source": [
        "The accuracy is accuracy score is 84%, "
      ]
    }
  ]
}